{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importing all the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import DataLoader,TensorDataset, random_split, WeightedRandomSampler\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "n3dGfzT8wn34"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('fall_processed.xlsx')\n",
        "print(data.columns)\n",
        "print(data.shape)\n",
        "application_id=data['Application Reference ID'].to_numpy()\n",
        "\n",
        "inputs=data.drop(['admitted','Application Reference ID'],axis=1).to_numpy()\n",
        "\n",
        "labels=data['admitted'].to_numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1631r9aWwsPe",
        "outputId": "cb0127a4-9de1-429d-b8d9-dc4fcee69172"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Application Reference ID', 'Application Major', 'Scholarship_Awarded',\n",
            "       'Application CGPA', 'FAFSA Filed', 'High School Code',\n",
            "       'Financial Aid Appeal', 'Accepted Student Day Event Attended',\n",
            "       'Campus Visits - Person', 'Campus Visits - App', 'Logins Before Admit',\n",
            "       'Acceptance Call Success', 'Application Consider Test Scores',\n",
            "       'Application ACRK', 'Waitlist Confirmed Date', 'Emails Sent',\n",
            "       'Emails Opened', 'Was Inquiry', 'Athlete', 'admitted',\n",
            "       'Application College_00', 'Application College_CAS',\n",
            "       'Application College_COB', 'Application College_HCLC',\n",
            "       'Application College_ID', 'Application College_SHS',\n",
            "       'Application College_TCOE', 'Application Housing_Commuter',\n",
            "       'Application Housing_Residential', 'Application Housing_nan',\n",
            "       'Application Enroll Status_Full Time',\n",
            "       'Application Enroll Status_Part Time', 'Application Span',\n",
            "       'Admission Span', 'Person Sex_F', 'Person Sex_M', 'Person Sex_nan',\n",
            "       'High School Region_Midwest', 'High School Region_Military',\n",
            "       'High School Region_Northeast', 'High School Region_South',\n",
            "       'High School Region_Southwest', 'High School Region_Territory',\n",
            "       'High School Region_West', 'Address 1 Region_Midwest',\n",
            "       'Address 1 Region_Military', 'Address 1 Region_Northeast',\n",
            "       'Address 1 Region_South', 'Address 1 Region_Southwest',\n",
            "       'Address 1 Region_Territory', 'Address 1 Region_West'],\n",
            "      dtype='object')\n",
            "(21865, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "    inputs, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "print(inputs.shape[1])\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_inputs = torch.from_numpy(train_inputs).float()\n",
        "test_inputs = torch.from_numpy(test_inputs).float()\n",
        "train_labels = torch.from_numpy(train_labels).int()\n",
        "test_labels = torch.from_numpy(test_labels).int()\n",
        "\n",
        "input_embedding_dimension = int(inputs[:, 0].max()) + 1  # 112\n",
        "input_hs_embedding_dimension = int(inputs[:, 4].max()) + 1\n",
        "\n",
        "print(input_embedding_dimension, input_hs_embedding_dimension)\n",
        "print(\"Max index in categorical column 0:\", inputs[:, 0].max(), \"Embedding dim:\", input_embedding_dimension)\n",
        "print(\"Max index in categorical column 4:\", inputs[:, 4].max(), \"Embedding dim:\", input_hs_embedding_dimension)\n",
        "print(\"Max index in train categorical column 4:\", train_inputs[:, 4].max())\n",
        "print(\"Max index in test categorical column 4:\", test_inputs[:, 4].max())\n",
        "\n",
        "train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "test_dataset = TensorDataset(test_inputs, test_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "print(\"Checking train_inputs for NaN:\", torch.any(torch.isnan(train_inputs)))\n",
        "print(\"Checking train_inputs for Inf:\", torch.any(torch.isinf(train_inputs)))\n",
        "print(\"Checking train_labels for NaN:\", torch.any(torch.isnan(train_labels)))\n",
        "print(\"Checking train_labels for Inf:\", torch.any(torch.isinf(train_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqHr7vfvgfgF",
        "outputId": "698489a6-5ac4-420b-95a7-5bdb79080649"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n",
            "112 4002\n",
            "Max index in categorical column 0: 111.0 Embedding dim: 112\n",
            "Max index in categorical column 4: 4001.0 Embedding dim: 4002\n",
            "Max index in train categorical column 4: tensor(4000.)\n",
            "Max index in test categorical column 4: tensor(4001.)\n",
            "Checking train_inputs for NaN: tensor(False)\n",
            "Checking train_inputs for Inf: tensor(False)\n",
            "Checking train_labels for NaN: tensor(False)\n",
            "Checking train_labels for Inf: tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, i, h_size, h_next_size, h_next_next_size=16, n_classes=2,\n",
        "                 how_many_layers=4, embedding_dim=300,hs_embedding_dim=300):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        features = i.shape[1]  # Total number of input features\n",
        "\n",
        "        self.major_embedding = nn.Embedding(input_embedding_dimension, embedding_dim)\n",
        "\n",
        "        #embedding layer for the high school codes\n",
        "        self.hs_embedding=nn.Embedding(input_hs_embedding_dimension,hs_embedding_dim)\n",
        "\n",
        "        print(f\"Setting major embedding dim: {input_embedding_dimension}\")\n",
        "        print(f\"Setting HS embedding dim: {input_hs_embedding_dimension}\")\n",
        "\n",
        "        # Input to fc1 will be (features - 2) continuous + embedding_dim\n",
        "        self.fc1 = nn.Linear(features - 2 + embedding_dim + hs_embedding_dim, h_size)\n",
        "        self.layers = how_many_layers\n",
        "\n",
        "        if self.layers == 2:\n",
        "            self.fc2 = nn.Linear(h_size, n_classes)\n",
        "        elif self.layers == 3:\n",
        "            self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "            self.fc4 = nn.Linear(h_next_size, n_classes)\n",
        "        elif self.layers == 4:\n",
        "            self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "            self.fc4 = nn.Linear(h_next_size, h_next_next_size)\n",
        "            self.fc5 = nn.Linear(h_next_next_size, n_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Ensure input is float and extract categorical/continuous features\n",
        "        categorical_input = X[:, 0].long()  # First column: categorical (encoded)\n",
        "        hs_input = X[:,4].long()\n",
        "\n",
        "        #continuous_input = X[:, 1:].float() # Rest: continuous features\n",
        "        continuous_indices = [i for i in range(X.shape[1]) if i not in [0, 4]]\n",
        "        continuous_input = X[:, continuous_indices].float()\n",
        "\n",
        "        # Apply embedding\n",
        "        embedded = self.major_embedding(categorical_input)  # Shape: [batch_size, embedding_dim]\n",
        "        hs_embedded = self.hs_embedding(hs_input)\n",
        "\n",
        "        # Concatenate with continuous features\n",
        "        X = torch.cat((embedded,hs_embedded, continuous_input), dim=1)  # Shape: [batch_size, embedding_dim + (features-1)]\n",
        "\n",
        "        if self.layers == 2:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = self.fc2(X)\n",
        "        elif self.layers == 3:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = F.relu(self.fc3(X))\n",
        "            X = self.fc4(X)\n",
        "        elif self.layers == 4:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = torch.tanh(self.fc3(X))\n",
        "            X = F.sigmoid(self.fc4(X))\n",
        "            X = self.fc5(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "net = NeuralNetwork(inputs, h_size=32, h_next_size=48, how_many_layers=3)\n",
        "print(f\"Expected input features to fc1: {train_inputs.shape[1] - 1 + 8}\")  # Debug print\n",
        "print(f\"fc1 weight shape: {net.fc1.weight.shape}\")  # Debug printn_epochs = 600\n",
        "\n",
        "\n",
        "n_epochs = 500\n",
        "learning_rate = 0.0001\n",
        "decay_rate = learning_rate / n_epochs\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
        "lambda_reg = 0.01\n",
        "lambda_entropy = 0\n",
        "\n",
        "\n",
        "def loss_fn(model, outputs, targets):\n",
        "    # Convert labels to numpy\n",
        "    y_train = train_labels.numpy()\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "    # Convert to PyTorch tensor\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "    cross_entropy = nn.functional.cross_entropy(outputs, targets,weight=class_weights_tensor)\n",
        "    l2_regularization = 0\n",
        "    entropy_regularization = 0\n",
        "\n",
        "    for param in model.parameters():\n",
        "        l2_regularization += torch.norm(param, p=2) ** 2\n",
        "        entropy_regularization += torch.mean(torch.sum(-outputs * torch.log(outputs), dim=1))\n",
        "\n",
        "    loss = cross_entropy + lambda_reg * l2_regularization\n",
        "    return loss\n",
        "\n",
        "def test_instance(model):\n",
        "    y_t = []\n",
        "    y_s = []\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss += loss_fn(model, outputs, labels.long())\n",
        "            y_t.extend(labels.numpy().astype('int'))\n",
        "            y_s.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "    acc = accuracy_score(y_t, y_s)\n",
        "    return loss, acc\n",
        "\n",
        "iteration = 0\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    total = 0  # No. of total predictions\n",
        "    correct = 0  # No. of correct predictions\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(net, outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)  # Loss in every epoch\n",
        "    epoch_acc = correct / total  # Accuracy for every epoch\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
        "        print(f'Epoch: {epoch + 1}/{n_epochs} | pLoss: {running_loss / len(inputs)} | Accuracy: {epoch_acc} | Loss: {epoch_loss}')\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        test_loss, test_acc = test_instance(net)\n",
        "        print(f'Epoch: {epoch + 1} | The test data Accuracy = {test_acc} | Test Loss = {test_loss}')\n",
        "\n",
        "        if counter < test_acc:\n",
        "            save_net = net\n",
        "            counter = test_acc\n",
        "\n",
        "y_true = []\n",
        "y_scores = []\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = save_net(inputs)\n",
        "        test_loss += loss_fn(net, outputs, labels.long())\n",
        "        y_true.extend(labels.numpy().astype('int'))\n",
        "        y_scores.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_scores)\n",
        "precision = precision_score(y_true, y_scores)\n",
        "recall = recall_score(y_true, y_scores)\n",
        "f1_val = f1_score(y_true, y_scores)\n",
        "auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_val))\n",
        "print('AUROC Score: {:.4f}'.format(auc_roc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQQbc3KdgiOC",
        "outputId": "56220f9c-6251-4026-f1b1-eb2cc97b1d0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting major embedding dim: 112\n",
            "Setting HS embedding dim: 4002\n",
            "Expected input features to fc1: 56\n",
            "fc1 weight shape: torch.Size([32, 647])\n",
            "Epoch: 1/500 | pLoss: 10585358.4140625 | Accuracy: 0.797736107935056 | Loss: 12103.085312214154\n",
            "Epoch: 1 | The test data Accuracy = 0.9208781157100389 | Test Loss = 816948.75\n",
            "Epoch: 11/500 | pLoss: 6852334.3765625 | Accuracy: 0.9552366796249714 | Loss: 7834.820919920535\n",
            "Epoch: 21/500 | pLoss: 4331766.458105469 | Accuracy: 0.9606677338211754 | Loss: 4952.85439984618\n",
            "Epoch: 31/500 | pLoss: 2632259.3038085937 | Accuracy: 0.9631831694488909 | Loss: 3009.672197357185\n",
            "Epoch: 41/500 | pLoss: 1530512.4579101563 | Accuracy: 0.9636976903727418 | Loss: 1749.9570751316674\n",
            "Epoch: 51/500 | pLoss: 849545.0588134766 | Accuracy: 0.9641550423050538 | Loss: 971.3526855859553\n",
            "Epoch: 51 | The test data Accuracy = 0.9602103818888634 | Test Loss = 64977.4140625\n",
            "Epoch: 61/500 | pLoss: 449284.1204040527 | Accuracy: 0.9642693802881317 | Loss: 513.7024015596304\n",
            "Epoch: 71/500 | pLoss: 226026.1800201416 | Accuracy: 0.9640407043219757 | Loss: 258.43377546323075\n",
            "Epoch: 81/500 | pLoss: 108052.87857208253 | Accuracy: 0.9639835353304368 | Loss: 123.54548201701637\n",
            "Epoch: 91/500 | pLoss: 49067.669167327884 | Accuracy: 0.9631831694488909 | Loss: 56.10298326929783\n",
            "Epoch: 101/500 | pLoss: 21171.316013717653 | Accuracy: 0.9616967756688772 | Loss: 24.206855721149843\n",
            "Epoch: 101 | The test data Accuracy = 0.962725817516579 | Test Loss = 1598.38134765625\n",
            "Epoch: 111/500 | pLoss: 8706.31060333252 | Accuracy: 0.9616967756688772 | Loss: 9.954619944354585\n",
            "Epoch: 121/500 | pLoss: 3451.922795534134 | Accuracy: 0.9621541276011891 | Loss: 3.9468589018227007\n",
            "Epoch: 131/500 | pLoss: 1352.3652089834213 | Accuracy: 0.96266864852504 | Loss: 1.546267103799933\n",
            "Epoch: 141/500 | pLoss: 552.3376464366913 | Accuracy: 0.962725817516579 | Loss: 0.6315317247160889\n",
            "Epoch: 151/500 | pLoss: 266.12801601886747 | Accuracy: 0.9617539446604162 | Loss: 0.3042854059214126\n",
            "Epoch: 151 | The test data Accuracy = 0.9675280128058541 | Test Loss = 20.695066452026367\n",
            "Epoch: 161/500 | pLoss: 173.4807444214821 | Accuracy: 0.9623828035673451 | Loss: 0.19835438420018534\n",
            "Epoch: 171/500 | pLoss: 148.1266693711281 | Accuracy: 0.9614109307111822 | Loss: 0.1693650461595336\n",
            "Epoch: 181/500 | pLoss: 142.08569512963294 | Accuracy: 0.9616396066773382 | Loss: 0.16245791805354784\n",
            "Epoch: 191/500 | pLoss: 140.30548233687878 | Accuracy: 0.962439972558884 | Loss: 0.16042245865181656\n",
            "Epoch: 201/500 | pLoss: 140.30871801376344 | Accuracy: 0.962611479533501 | Loss: 0.1604261582595054\n",
            "Epoch: 201 | The test data Accuracy = 0.9579236222273039 | Test Loss = 11.102823257446289\n",
            "Epoch: 211/500 | pLoss: 140.39362832903862 | Accuracy: 0.962954493482735 | Loss: 0.1605232430014162\n",
            "Epoch: 221/500 | pLoss: 139.83823839277028 | Accuracy: 0.9612394237365652 | Loss: 0.15988822135006894\n",
            "Epoch: 231/500 | pLoss: 141.0337652117014 | Accuracy: 0.9607249028127144 | Loss: 0.16125516260199108\n",
            "Epoch: 241/500 | pLoss: 139.99530254602433 | Accuracy: 0.9616396066773382 | Loss: 0.1600678053350381\n",
            "Epoch: 251/500 | pLoss: 140.2761472195387 | Accuracy: 0.9618111136519552 | Loss: 0.16038891747031636\n",
            "Epoch: 251 | The test data Accuracy = 0.96775668877201 | Test Loss = 11.390331268310547\n",
            "Epoch: 261/500 | pLoss: 139.6428436100483 | Accuracy: 0.9617539446604162 | Loss: 0.159664810896465\n",
            "Epoch: 271/500 | pLoss: 139.2689348936081 | Accuracy: 0.9630116624742739 | Loss: 0.15923729121153452\n",
            "Epoch: 281/500 | pLoss: 139.7592729449272 | Accuracy: 0.9634118454150469 | Loss: 0.15979793384967667\n",
            "Epoch: 291/500 | pLoss: 140.60855709910393 | Accuracy: 0.9624971415504231 | Loss: 0.16076898822216318\n",
            "Epoch: 301/500 | pLoss: 139.53827583789825 | Accuracy: 0.962725817516579 | Loss: 0.15954525021483906\n",
            "Epoch: 301 | The test data Accuracy = 0.9583809741596159 | Test Loss = 11.055411338806152\n",
            "Epoch: 311/500 | pLoss: 139.95293056964874 | Accuracy: 0.9619826206265721 | Loss: 0.16001935807186\n",
            "Epoch: 321/500 | pLoss: 141.63650895208121 | Accuracy: 0.9614109307111822 | Loss: 0.16194432763787012\n",
            "Epoch: 331/500 | pLoss: 139.700461705029 | Accuracy: 0.96266864852504 | Loss: 0.1597306902641539\n",
            "Epoch: 341/500 | pLoss: 140.31800462305546 | Accuracy: 0.962439972558884 | Loss: 0.16043677638126624\n",
            "Epoch: 351/500 | pLoss: 140.41095121502877 | Accuracy: 0.9624971415504231 | Loss: 0.16054304963986823\n",
            "Epoch: 351 | The test data Accuracy = 0.9595243539903956 | Test Loss = 11.01412296295166\n",
            "Epoch: 361/500 | pLoss: 140.19671351909636 | Accuracy: 0.962782986508118 | Loss: 0.1602980945793464\n",
            "Epoch: 371/500 | pLoss: 140.36605710983275 | Accuracy: 0.9619826206265721 | Loss: 0.16049171862546624\n",
            "Epoch: 381/500 | pLoss: 139.86734107881784 | Accuracy: 0.9617539446604162 | Loss: 0.15992149677431722\n",
            "Epoch: 391/500 | pLoss: 140.0737766444683 | Accuracy: 0.962840155499657 | Loss: 0.16015753103643757\n",
            "Epoch: 401/500 | pLoss: 140.5114821970463 | Accuracy: 0.9614680997027213 | Loss: 0.16065799473707557\n",
            "Epoch: 401 | The test data Accuracy = 0.9624971415504231 | Test Loss = 11.04649543762207\n",
            "Epoch: 411/500 | pLoss: 139.69841658473015 | Accuracy: 0.9613537617196433 | Loss: 0.15972835191485268\n",
            "Epoch: 421/500 | pLoss: 140.19269083887338 | Accuracy: 0.9624971415504231 | Loss: 0.16029349512791377\n",
            "Epoch: 431/500 | pLoss: 140.02606218159198 | Accuracy: 0.9624971415504231 | Loss: 0.1601029752819483\n",
            "Epoch: 441/500 | pLoss: 139.80758152604102 | Accuracy: 0.9620397896181111 | Loss: 0.1598531689069758\n",
            "Epoch: 451/500 | pLoss: 139.54341079294682 | Accuracy: 0.9619826206265721 | Loss: 0.15955112141887356\n",
            "Epoch: 451 | The test data Accuracy = 0.9611250857534873 | Test Loss = 11.025933265686035\n",
            "Epoch: 461/500 | pLoss: 140.7045947790146 | Accuracy: 0.96266864852504 | Loss: 0.16087879576836792\n",
            "Epoch: 471/500 | pLoss: 138.86151086986064 | Accuracy: 0.9621541276011891 | Loss: 0.15877145080020655\n",
            "Epoch: 481/500 | pLoss: 140.368545794487 | Accuracy: 0.9618111136519552 | Loss: 0.16049456413730506\n",
            "Epoch: 491/500 | pLoss: 140.09106085002423 | Accuracy: 0.9619826206265721 | Loss: 0.16017729344846127\n",
            "Epoch: 500/500 | pLoss: 140.8870542049408 | Accuracy: 0.9614109307111822 | Loss: 0.1610874161959076\n",
            "Accuracy: 0.9614\n",
            "Precision: 0.7819\n",
            "Recall: 0.9791\n",
            "F1 Score: 0.8695\n",
            "AUROC Score: 0.9689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "data_2025 = pd.read_excel('/content/Fall 2025 3.18.25_processed.xlsx')\n",
        "# Ensure that new_data has the same columns as the training data except for the target column\n",
        "print(data_2025.columns)\n",
        "\n",
        "new_data = data_2025[data_2025.drop(['admitted','Application Reference ID'], axis=1).columns]\n",
        "\n",
        "print(new_data.shape[1])\n",
        "data_2025_labels = data_2025['admitted'].to_numpy()\n",
        "\n",
        "# Make sure new_data is a PyTorch tensor\n",
        "new_data_tensor = torch.from_numpy(new_data.to_numpy()).float()\n",
        "\n",
        "# Perform inference on the new data\n",
        "with torch.no_grad():\n",
        "    # Assuming your model is saved in 'save_net' after training\n",
        "    outputs = save_net(new_data_tensor)\n",
        "\n",
        "# Get predicted class labels from the outputs\n",
        "predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "# If you want the predicted probabilities, you can use:\n",
        "# probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "# Convert predictions to numpy for further processing\n",
        "predictions = predictions.numpy()\n",
        "\n",
        "print(\"Predictions on new data:\")\n",
        "print(predictions)\n",
        "total_predictions=len(predictions)\n",
        "count_ones = (predictions == 1).sum()\n",
        "print(f\"Number of 1s in predictions: {count_ones}\")\n",
        "print(f\"Number of 0s in predictions: {total_predictions - count_ones}\")\n",
        "print(f\"Total number of predictions: {total_predictions}\")\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(data_2025_labels,predictions)\n",
        "precision = precision_score(data_2025_labels,predictions)\n",
        "recall = recall_score(data_2025_labels, predictions)\n",
        "f1_val = f1_score(data_2025_labels, predictions)\n",
        "auc_roc = roc_auc_score(data_2025_labels, predictions)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_val))\n",
        "print('AUROC Score: {:.4f}'.format(auc_roc))\n",
        "\n",
        "\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(data_2025_labels,predictions)\n",
        "\n",
        "# Print the matrix\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot the Confusion Matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(data_2025_labels,predictions)\n",
        "\n",
        "# Extract TP, TN, FP, FN\n",
        "TN = cm[0, 0]  # True Negative\n",
        "FP = cm[0, 1]  # False Positive\n",
        "FN = cm[1, 0]  # False Negative\n",
        "TP = cm[1, 1]  # True Positive\n",
        "\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KKQQHbwVw0aR",
        "outputId": "251b3301-8049-4335-9b22-59d322d3703d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Application Reference ID', 'Application Major', 'Scholarship_Awarded',\n",
            "       'Application CGPA', 'FAFSA Filed', 'High School Code',\n",
            "       'Financial Aid Appeal', 'Accepted Student Day Event Attended',\n",
            "       'Campus Visits - Person', 'Campus Visits - App', 'Logins Before Admit',\n",
            "       'Acceptance Call Success', 'Application Consider Test Scores',\n",
            "       'Application ACRK', 'Waitlist Confirmed Date', 'Emails Sent',\n",
            "       'Emails Opened', 'Was Inquiry', 'Athlete', 'admitted',\n",
            "       'Application College_00', 'Application College_CAS',\n",
            "       'Application College_COB', 'Application College_HCLC',\n",
            "       'Application College_ID', 'Application College_SHS',\n",
            "       'Application College_TCOE', 'Application Housing_Commuter',\n",
            "       'Application Housing_Residential', 'Application Housing_nan',\n",
            "       'Application Enroll Status_Full Time',\n",
            "       'Application Enroll Status_Part Time', 'Application Span',\n",
            "       'Admission Span', 'Person Sex_F', 'Person Sex_M', 'Person Sex_Unknown',\n",
            "       'High School Region_Midwest', 'High School Region_Military',\n",
            "       'High School Region_Northeast', 'High School Region_South',\n",
            "       'High School Region_Southwest', 'High School Region_Territory',\n",
            "       'High School Region_West', 'Address 1 Region_Midwest',\n",
            "       'Address 1 Region_Military', 'Address 1 Region_Northeast',\n",
            "       'Address 1 Region_South', 'Address 1 Region_Southwest',\n",
            "       'Address 1 Region_Territory', 'Address 1 Region_West'],\n",
            "      dtype='object')\n",
            "49\n",
            "Predictions on new data:\n",
            "[0 0 0 ... 0 0 0]\n",
            "Number of 1s in predictions: 811\n",
            "Number of 0s in predictions: 11431\n",
            "Total number of predictions: 12242\n",
            "Accuracy: 0.9422\n",
            "Precision: 0.2848\n",
            "Recall: 0.6453\n",
            "F1 Score: 0.3952\n",
            "AUROC Score: 0.7982\n",
            "Confusion Matrix:\n",
            " [[11304   580]\n",
            " [  127   231]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives (TP): 231\n",
            "False Positives (FP): 580\n",
            "True Negatives (TN): 11304\n",
            "False Negatives (FN): 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(save_net, \"/content/predictionsiwth756&accuracy78.pth\")"
      ],
      "metadata": {
        "id": "PWzegJlOghI7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3JDYEhgpwZ8l"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# class NeuralNetwork(nn.Module):\n",
        "#     def __init__(self, i, h_size, h_next_size, h_next_next_size=24, n_classes=2,\n",
        "#                  how_many_layers=4, embedding_dim=300,hs_embedding_dim=300):\n",
        "#         super(NeuralNetwork, self).__init__()\n",
        "\n",
        "#         features = i.shape[1]  # Total number of input features\n",
        "\n",
        "#         self.major_embedding = nn.Embedding(input_embedding_dimension, embedding_dim)\n",
        "\n",
        "#         #embedding layer for the high school codes\n",
        "#         self.hs_embedding=nn.Embedding(input_hs_embedding_dimension,hs_embedding_dim)\n",
        "\n",
        "#         print(f\"Setting major embedding dim: {input_embedding_dimension}\")\n",
        "#         print(f\"Setting HS embedding dim: {input_hs_embedding_dimension}\")\n",
        "\n",
        "#         # Input to fc1 will be (features - 2) continuous + embedding_dim\n",
        "#         self.fc1 = nn.Linear(features - 2 + embedding_dim + hs_embedding_dim, h_size)\n",
        "#         self.layers = how_many_layers\n",
        "\n",
        "#         if self.layers == 2:\n",
        "#             self.fc2 = nn.Linear(h_size, n_classes)\n",
        "#         elif self.layers == 3:\n",
        "#             self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "#             self.fc4 = nn.Linear(h_next_size, n_classes)\n",
        "#         elif self.layers == 4:\n",
        "#             self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "#             self.fc4 = nn.Linear(h_next_size, h_next_next_size)\n",
        "#             self.fc5 = nn.Linear(h_next_next_size, n_classes)\n",
        "\n",
        "#     def forward(self, X):\n",
        "#         # Ensure input is float and extract categorical/continuous features\n",
        "#         categorical_input = X[:, 0].long()  # First column: categorical (encoded)\n",
        "#         hs_input = X[:,4].long()\n",
        "\n",
        "#         #continuous_input = X[:, 1:].float() # Rest: continuous features\n",
        "#         continuous_indices = [i for i in range(X.shape[1]) if i not in [0, 4]]\n",
        "#         continuous_input = X[:, continuous_indices].float()\n",
        "\n",
        "#         # Apply embedding\n",
        "#         embedded = self.major_embedding(categorical_input)  # Shape: [batch_size, embedding_dim]\n",
        "#         hs_embedded = self.hs_embedding(hs_input)\n",
        "\n",
        "#         # Concatenate with continuous features\n",
        "#         X = torch.cat((embedded,hs_embedded, continuous_input), dim=1)  # Shape: [batch_size, embedding_dim + (features-1)]\n",
        "\n",
        "#         if self.layers == 2:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = self.fc2(X)\n",
        "#         elif self.layers == 3:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = F.relu(self.fc3(X))\n",
        "#             X = self.fc4(X)\n",
        "#         elif self.layers == 4:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = torch.tanh(self.fc3(X))\n",
        "#             X = F.sigmoid(self.fc4(X))\n",
        "#             X = self.fc5(X)\n",
        "\n",
        "#         return X\n",
        "\n",
        "\n",
        "# net = NeuralNetwork(inputs, h_size=40, h_next_size=32, how_many_layers=3)\n",
        "# print(f\"Expected input features to fc1: {train_inputs.shape[1] - 1 + 8}\")  # Debug print\n",
        "# print(f\"fc1 weight shape: {net.fc1.weight.shape}\")  # Debug printn_epochs = 600\n",
        "\n",
        "\n",
        "# n_epochs = 600\n",
        "# learning_rate = 0.0001\n",
        "# decay_rate = learning_rate / n_epochs\n",
        "# optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
        "# lambda_reg = 0.001\n",
        "# lambda_entropy = 0\n",
        "\n",
        "\n",
        "# def loss_fn(model, outputs, targets):\n",
        "#     # Convert labels to numpy\n",
        "#     y_train = train_labels.numpy()\n",
        "\n",
        "#     # Compute class weights\n",
        "#     class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "#     # Convert to PyTorch tensor\n",
        "#     class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "#     cross_entropy = nn.functional.cross_entropy(outputs, targets,weight=class_weights_tensor)\n",
        "#     l2_regularization = 0\n",
        "#     entropy_regularization = 0\n",
        "\n",
        "#     for param in model.parameters():\n",
        "#         l2_regularization += torch.norm(param, p=2) ** 2\n",
        "#         entropy_regularization += torch.mean(torch.sum(-outputs * torch.log(outputs), dim=1))\n",
        "\n",
        "#     loss = cross_entropy + lambda_reg * l2_regularization\n",
        "#     return loss\n",
        "\n",
        "# def test_instance(model):\n",
        "#     y_t = []\n",
        "#     y_s = []\n",
        "#     loss = 0\n",
        "#     acc = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, labels in test_loader:\n",
        "#             outputs = model(inputs)\n",
        "#             loss += loss_fn(model, outputs, labels.long())\n",
        "#             y_t.extend(labels.numpy().astype('int'))\n",
        "#             y_s.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "#     acc = accuracy_score(y_t, y_s)\n",
        "#     return loss, acc\n",
        "\n",
        "# iteration = 0\n",
        "# counter = 0\n",
        "\n",
        "# for epoch in range(n_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     total = 0  # No. of total predictions\n",
        "#     correct = 0  # No. of correct predictions\n",
        "\n",
        "#     for i, (inputs, labels) in enumerate(train_loader):\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = net(inputs)\n",
        "#         loss = loss_fn(net, outputs, labels.long())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item() * inputs.size(0)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "#     epoch_loss = running_loss / len(train_loader.dataset)  # Loss in every epoch\n",
        "#     epoch_acc = correct / total  # Accuracy for every epoch\n",
        "\n",
        "#     if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
        "#         print(f'Epoch: {epoch + 1}/{n_epochs} | pLoss: {running_loss / len(inputs)} | Accuracy: {epoch_acc} | Loss: {epoch_loss}')\n",
        "\n",
        "#     if epoch % 50 == 0:\n",
        "#         test_loss, test_acc = test_instance(net)\n",
        "#         print(f'Epoch: {epoch + 1} | The test data Accuracy = {test_acc} | Test Loss = {test_loss}')\n",
        "\n",
        "#         if counter < test_acc:\n",
        "#             save_net = net\n",
        "#             counter = test_acc\n",
        "\n",
        "# y_true = []\n",
        "# y_scores = []\n",
        "# test_loss = 0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in test_loader:\n",
        "#         outputs = save_net(inputs)\n",
        "#         test_loss += loss_fn(net, outputs, labels.long())\n",
        "#         y_true.extend(labels.numpy().astype('int'))\n",
        "#         y_scores.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "\n",
        "# accuracy = accuracy_score(y_true, y_scores)\n",
        "# precision = precision_score(y_true, y_scores)\n",
        "# recall = recall_score(y_true, y_scores)\n",
        "# f1_val = f1_score(y_true, y_scores)\n",
        "# auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "# print('Accuracy: {:.4f}'.format(accuracy))\n",
        "# print('Precision: {:.4f}'.format(precision))\n",
        "# print('Recall: {:.4f}'.format(recall))\n",
        "# print('F1 Score: {:.4f}'.format(f1_val))\n",
        "# print('AUROC Score: {:.4f}'.format(auc_roc))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import torch\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# data_2025 = pd.read_excel('/content/Fall 2025 3.12.25_processed_1.xlsx')\n",
        "# # Ensure that new_data has the same columns as the training data except for the target column\n",
        "# print(data_2025.columns)\n",
        "\n",
        "# new_data = data_2025[data_2025.drop(['admitted','Application Reference ID'], axis=1).columns]\n",
        "\n",
        "# print(new_data.shape[1])\n",
        "# data_2025_labels = data_2025['admitted'].to_numpy()\n",
        "\n",
        "# # Make sure new_data is a PyTorch tensor\n",
        "# new_data_tensor = torch.from_numpy(new_data.to_numpy()).float()\n",
        "\n",
        "# # Perform inference on the new data\n",
        "# with torch.no_grad():\n",
        "#     # Assuming your model is saved in 'save_net' after training\n",
        "#     outputs = save_net(new_data_tensor)\n",
        "\n",
        "# # Get predicted class labels from the outputs\n",
        "# predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "# # If you want the predicted probabilities, you can use:\n",
        "# # probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "# # Convert predictions to numpy for further processing\n",
        "# predictions = predictions.numpy()\n",
        "\n",
        "# print(\"Predictions on new data:\")\n",
        "# print(predictions)\n",
        "# total_predictions=len(predictions)\n",
        "# count_ones = (predictions == 1).sum()\n",
        "# print(f\"Number of 1s in predictions: {count_ones}\")\n",
        "# print(f\"Number of 0s in predictions: {total_predictions - count_ones}\")\n",
        "# print(f\"Total number of predictions: {total_predictions}\")\n",
        "\n",
        "\n",
        "# accuracy = accuracy_score(data_2025_labels,predictions)\n",
        "# precision = precision_score(data_2025_labels,predictions)\n",
        "# recall = recall_score(data_2025_labels, predictions)\n",
        "# f1_val = f1_score(data_2025_labels, predictions)\n",
        "# auc_roc = roc_auc_score(data_2025_labels, predictions)\n",
        "\n",
        "# print('Accuracy: {:.4f}'.format(accuracy))\n",
        "# print('Precision: {:.4f}'.format(precision))\n",
        "# print('Recall: {:.4f}'.format(recall))\n",
        "# print('F1 Score: {:.4f}'.format(f1_val))\n",
        "# print('AUROC Score: {:.4f}'.format(auc_roc))\n",
        "\n",
        "\n",
        "\n",
        "# # Compute Confusion Matrix\n",
        "# cm = confusion_matrix(data_2025_labels,predictions)\n",
        "\n",
        "# # Print the matrix\n",
        "# print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# # Plot the Confusion Matrix\n",
        "# plt.figure(figsize=(6, 5))\n",
        "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "# plt.xlabel(\"Predicted Label\")\n",
        "# plt.ylabel(\"True Label\")\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.show()\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# # Compute Confusion Matrix\n",
        "# cm = confusion_matrix(data_2025_labels,predictions)\n",
        "\n",
        "# # Extract TP, TN, FP, FN\n",
        "# TN = cm[0, 0]  # True Negative\n",
        "# FP = cm[0, 1]  # False Positive\n",
        "# FN = cm[1, 0]  # False Negative\n",
        "# TP = cm[1, 1]  # True Positive\n",
        "\n",
        "# print(f\"True Positives (TP): {TP}\")\n",
        "# print(f\"False Positives (FP): {FP}\")\n",
        "# print(f\"True Negatives (TN): {TN}\")\n",
        "# print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p0Nk0b89zkIM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcyE7dkY9Kf4"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}