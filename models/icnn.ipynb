{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "metadata": {
        "id": "E8dw_MVvB9FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "FnHUFSPNQ2qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('/content/fall_processed_norm.xlsx')\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIkM_W_0UF7K",
        "outputId": "10d12c94-6c24-4509-c425-ec651900fe89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Application Reference ID', 'Application Major', 'Scholarship_Awarded',\n",
              "       'Application CGPA', 'FAFSA Filed', 'High School Code',\n",
              "       'Financial Aid Appeal', 'Accepted Student Day Event Attended',\n",
              "       'Campus Visits - Person', 'Campus Visits - App', 'Logins Before Admit',\n",
              "       'Acceptance Call Success', 'Application Consider Test Scores',\n",
              "       'Application ACRK', 'Waitlist Confirmed Date', 'Emails Sent',\n",
              "       'Emails Opened', 'Was Inquiry', 'Athlete', 'admitted',\n",
              "       'Application College_00', 'Application College_CAS',\n",
              "       'Application College_COB', 'Application College_HCLC',\n",
              "       'Application College_ID', 'Application College_SHS',\n",
              "       'Application College_TCOE', 'Application Housing_Commuter',\n",
              "       'Application Housing_Residential', 'Application Housing_nan',\n",
              "       'Application Enroll Status_Full Time',\n",
              "       'Application Enroll Status_Part Time', 'Application Span',\n",
              "       'Admission Span', 'Person Sex_F', 'Person Sex_M', 'Person Sex_Unknown',\n",
              "       'High School Region_Midwest', 'High School Region_Military',\n",
              "       'High School Region_Northeast', 'High School Region_South',\n",
              "       'High School Region_Southwest', 'High School Region_Territory',\n",
              "       'High School Region_West', 'Address 1 Region_Midwest',\n",
              "       'Address 1 Region_Military', 'Address 1 Region_Northeast',\n",
              "       'Address 1 Region_South', 'Address 1 Region_Southwest',\n",
              "       'Address 1 Region_Territory', 'Address 1 Region_West'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=data.drop(['Application Reference ID','admitted'],axis=1).to_numpy()\n",
        "labels=data['admitted'].to_numpy()\n",
        "app_id=data['Application Reference ID']\n",
        "inputs=torch.from_numpy(inputs).float()\n",
        "unique_majors = int(inputs[:, 0].max()) + 1  # 112\n",
        "unique_highschools = int(inputs[:, 4].max()) + 1\n",
        "print(inputs.shape[1],unique_majors,unique_highschools)\n",
        "#make sure to convert the type to long as tensors deal with the long integer which are 64 bit not the 32 bit\n",
        "labels=torch.from_numpy(labels).long()\n",
        "#creates a dataset tensor for each label example can be seen below how it works\n",
        "dataset=TensorDataset(inputs,labels)\n",
        "#convert the train_size to integer as operation results in float\n",
        "train_size=int((0.8*(len(dataset))))\n",
        "test_size=len(dataset)-train_size\n",
        "#print(train_size,test_size)\n",
        "#split the data randomly and specify the length by using the array of training and testing size\n",
        "train_dataset,test_dataset=random_split(dataset,[train_size-1,test_size+1])\n",
        "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=True)\n"
      ],
      "metadata": {
        "id": "vVrEnqQyUqYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aed9bdc-c5f1-49b4-a094-d76d40a51ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 112 4002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import torch\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# # Creating sample data\n",
        "# inputs = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])  # Features\n",
        "# labels = torch.tensor([0, 1, 0])  # Target labels\n",
        "\n",
        "# # Creating TensorDataset\n",
        "# dataset = TensorDataset(inputs, labels)\n",
        "\n",
        "# # Accessing data\n",
        "# print(dataset[0])  # Output: (tensor([1., 2.]), tensor(0))\n",
        "\n",
        "# # Creating a DataLoader for batch processing\n",
        "# dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# # Iterating over DataLoader\n",
        "# for batch in dataloader:\n",
        "#     x, y = batch\n",
        "#     print(\"Batch X:\", x)\n",
        "#     print(\"Batch Y:\", y)\n"
      ],
      "metadata": {
        "id": "JK5b1m77XAX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**kwargs(keyword arguments)<br>\n",
        "class ConvexNet(torch.nn.Module):<br>\n",
        "    def __init__(self, **kwargs):<br>\n",
        "net = ConvexNet(size=[133, 512, 16, 2], use_dout=[True, 0.3])<br>\n",
        "Behind the scenes, kwargs is:<br>\n",
        "{\n",
        "    \"size\": [133, 512, 16, 2],\\\n",
        "    \"use_dout\": [True, 0.3]\\\n",
        "}\n"
      ],
      "metadata": {
        "id": "ciFEU1cEaF4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "class ConvexNet(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ConvexNet, self).__init__()\n",
        "        torch.manual_seed(2)\n",
        "\n",
        "        self.embedding_dim = 300\n",
        "        unique_majors, unique_highschools = kwargs[\"unique_majors\"], kwargs[\"unique_highschools\"]\n",
        "\n",
        "\n",
        "        layer_sizes = kwargs[\"size\"] # [n_input, n_hidden_1, n_hidden_2, n_output]\n",
        "        # inputs = layer_sizes[0]\n",
        "        # print(layer_sizes[0])\n",
        "        layer_sizes[0]=(inputs- 2 + 2*self.embedding_dim)\n",
        "        # print(layer_sizes[0])\n",
        "        # Embedding layers for the categorical variables\n",
        "        self.major_embedding = nn.Embedding(unique_majors, self.embedding_dim)\n",
        "        self.hs_embedding = nn.Embedding(unique_highschools, self.embedding_dim)\n",
        "\n",
        "\n",
        "        self.W = nn.ParameterList([nn.Parameter(torch.Tensor(l, layer_sizes[0]))\n",
        "                                   for l in layer_sizes[1:]])\n",
        "        self.U = nn.ParameterList([nn.Parameter(torch.Tensor(layer_sizes[i + 1], layer_sizes[i]))\n",
        "                                   for i in range(1, len(layer_sizes) - 1)])\n",
        "        self.bias = nn.ParameterList([nn.Parameter(torch.Tensor(layer_sizes[i+1])) for i in range(len(layer_sizes)-1)])\n",
        "\n",
        "        self.act = F.relu\n",
        "        self.use_dout = kwargs[\"use_dout\"][0]\n",
        "        self.dropout = nn.Dropout(p=kwargs[\"use_dout\"][1])\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Initialize weights using kaiming initialization\n",
        "        for W in self.W:\n",
        "            nn.init.kaiming_uniform_(W, a=5 ** 0.5)\n",
        "        for U in self.U:\n",
        "            nn.init.kaiming_uniform_(U, a=5 ** 0.5)\n",
        "        for i, b in enumerate(self.bias):\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W[i])\n",
        "            bound = 1 / (fan_in ** 0.5)\n",
        "            nn.init.uniform_(b, -bound, bound)\n",
        "    def forward(self, x):\n",
        "        # Separate the categorical and continuous inputs\n",
        "        categorical_input_1 = x[:, 0].long()  # Application Major\n",
        "        categorical_input_2 = x[:, 4].long()  # High school input (another categorical feature)\n",
        "\n",
        "        continuous_indices = [i for i in range(x.shape[1]) if i not in [0, 4]]\n",
        "        continuous_input = x[:, continuous_indices].float()  # The rest: continuous features\n",
        "\n",
        "        # Apply embedding layers for categorical inputs\n",
        "        major_embeddings = self.major_embedding(categorical_input_1)\n",
        "        #print(major_embeddings.shape)\n",
        "        hs_embeddings = self.hs_embedding(categorical_input_2)\n",
        "        #print(hs_embeddings.shape)\n",
        "        # Concatenate embeddings with continuous inputs\n",
        "        x = torch.cat((major_embeddings, hs_embeddings, continuous_input), dim=1)\n",
        "        #print(x.shape)\n",
        "\n",
        "        z = F.linear(x, self.W[0], self.bias[0])\n",
        "        z = self.act(z)\n",
        "        if self.use_dout:\n",
        "            z = self.dropout(z)\n",
        "\n",
        "        for W, b, U in zip(self.W[1:-1], self.bias[1:-1], self.U[:-1]):\n",
        "            z = F.linear(x, W, b) + F.linear(z, F.softplus(U)) / U.shape[0]\n",
        "            z = self.act(z)\n",
        "            if self.use_dout:\n",
        "                z = self.dropout(z)\n",
        "\n",
        "        out = F.linear(x, self.W[-1], self.bias[-1]) + F.linear(z, F.softplus(self.U[-1])) / self.U[-1].shape[0]\n",
        "\n",
        "        return out\n",
        "\n",
        "unique_majors=int(inputs[:, 0].max()) + 1  # 112\n",
        "unique_highschools = int(inputs[:, 4].max()) + 1 #4002\n",
        "\n",
        "\n",
        "inputs=inputs.shape[1]\n",
        "layer_sizes = [inputs, 512, 16, 2]  # [input_size, hidden_1, hidden_2, output_size]\n",
        "use_dout = (True, 0.5)  # Use dropout with a probability of 0.5\n",
        "\n",
        "# Initialize the model\n",
        "net = ConvexNet(size=layer_sizes, unique_majors=unique_majors, unique_highschools=unique_highschools, use_dout=use_dout)\n",
        "\n",
        "# Print the model architecture (optional)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "nvcBIPpvXAvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1a4dd1-65a0-4104-b9d1-121a7cb50bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvexNet(\n",
            "  (major_embedding): Embedding(112, 300)\n",
            "  (hs_embedding): Embedding(4002, 300)\n",
            "  (W): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512x647]\n",
            "      (1): Parameter containing: [torch.float32 of size 16x647]\n",
            "      (2): Parameter containing: [torch.float32 of size 2x647]\n",
            "  )\n",
            "  (U): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 16x512]\n",
            "      (1): Parameter containing: [torch.float32 of size 2x16]\n",
            "  )\n",
            "  (bias): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512]\n",
            "      (1): Parameter containing: [torch.float32 of size 16]\n",
            "      (2): Parameter containing: [torch.float32 of size 2]\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 500\n",
        "learning_rate = 0.001\n",
        "decay_rate = learning_rate / n_epochs\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
        "\n",
        "lambda_reg = 0.001\n",
        "lambda_entropy = 0\n",
        "def loss_fn(model, outputs, targets):\n",
        "    cross_entropy = nn.functional.cross_entropy(outputs, targets)\n",
        "    l2_regularization = 0\n",
        "    entropy_regularization = 0\n",
        "    for param in model.parameters():\n",
        "        l2_regularization += torch.norm(param, p=2) ** 2\n",
        "        entropy_regularization += torch.mean(torch.sum(-outputs * torch.log(outputs), dim=1))\n",
        "    loss = cross_entropy + lambda_reg * l2_regularization\n",
        "    return loss\n",
        "\n",
        "def test_instance(model):\n",
        "    y_t = []\n",
        "    y_s = []\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = net(inputs)\n",
        "            loss += loss_fn(model, outputs, labels.long())\n",
        "            y_t.extend(labels.numpy().astype('int'))\n",
        "            y_s.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "    acc = accuracy_score(y_t, y_s)\n",
        "    return loss, acc\n",
        "\n",
        "iteration = 0\n",
        "counter = 0\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    total = 0  # No. of total predictions\n",
        "    correct = 0  # No. of correct predictions\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(net, outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)  # Loss in every epoch\n",
        "    epoch_acc = correct / total  # Accuracy for every epoch\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
        "\n",
        "        print(f'Epoch: {epoch + 1}/500 | Loss: {running_loss / len(inputs)} | Accuracy: {epoch_acc}')\n",
        "        test_loss, test_acc = test_instance(net)\n",
        "        if (test_acc > 0.80) and (counter < test_acc):\n",
        "            print(\"Model saved at test accuracy = \", test_acc)\n",
        "            torch.save(net.state_dict(), '/content/best.pth')\n",
        "            save_net = net\n",
        "            counter = test_acc\n",
        "    if epoch % 50 == 0:\n",
        "        print(f'Epoch: {epoch + 1} | The test data Accuracy = {test_acc} | Test Loss = {test_loss}')\n",
        "\n",
        "y_true = []\n",
        "y_scores = []\n",
        "test_loss = 0\n",
        "\n",
        "save_net.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = save_net(inputs)\n",
        "        test_loss += loss_fn(save_net, outputs, labels.long())\n",
        "        y_true.extend(labels.numpy().astype('int'))\n",
        "        y_scores.extend(torch.sigmoid(outputs).max(axis = 1).indices.numpy())\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_scores)\n",
        "precision = precision_score(y_true,y_scores)\n",
        "recall = recall_score(y_true, y_scores)\n",
        "f1_val = f1_score(y_true, y_scores)\n",
        "auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_val))\n",
        "print('AUROC Score: {:.4f}'.format(auc_roc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMjdbwDkyzNH",
        "outputId": "5724ec9a-a85b-4198-88bd-129540f26168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/500 | Loss: 921883.0205592106 | Accuracy: 0.8630152649934252\n",
            "Model saved at test accuracy =  0.8877457704618198\n",
            "Epoch: 1 | The test data Accuracy = 0.8877457704618198 | Test Loss = 55249.1953125\n",
            "Epoch: 11/500 | Loss: 10273.215773381686 | Accuracy: 0.9392830598593562\n",
            "Model saved at test accuracy =  0.936671239140375\n",
            "Epoch: 21/500 | Loss: 176.70035007282308 | Accuracy: 0.9516322680235549\n",
            "Model saved at test accuracy =  0.9519890260631001\n",
            "Epoch: 31/500 | Loss: 158.107437257704 | Accuracy: 0.9623806529072094\n",
            "Model saved at test accuracy =  0.9554183813443072\n",
            "Epoch: 41/500 | Loss: 152.96392708859946 | Accuracy: 0.9651249213881424\n",
            "Epoch: 51/500 | Loss: 152.10651862621307 | Accuracy: 0.9639814761877536\n",
            "Epoch: 51 | The test data Accuracy = 0.9513031550068587 | Test Loss = 13.22206974029541\n",
            "Epoch: 61/500 | Loss: 152.49347749352455 | Accuracy: 0.9660396775484535\n",
            "Epoch: 71/500 | Loss: 152.98000542741073 | Accuracy: 0.9660968498084729\n",
            "Epoch: 81/500 | Loss: 147.07012703544214 | Accuracy: 0.9677548453490367\n",
            "Epoch: 91/500 | Loss: 149.43532559589335 | Accuracy: 0.9674689840489394\n",
            "Model saved at test accuracy =  0.9561042524005487\n",
            "Epoch: 101/500 | Loss: 149.52230054296945 | Accuracy: 0.9675261563089589\n",
            "Epoch: 101 | The test data Accuracy = 0.9519890260631001 | Test Loss = 13.477314949035645\n",
            "Epoch: 111/500 | Loss: 149.88016024388764 | Accuracy: 0.9673546395289006\n",
            "Epoch: 121/500 | Loss: 152.62341180208483 | Accuracy: 0.9660396775484535\n",
            "Epoch: 131/500 | Loss: 147.80258539946456 | Accuracy: 0.9666685724086673\n",
            "Epoch: 141/500 | Loss: 153.65383189759757 | Accuracy: 0.9659253330284147\n",
            "Epoch: 151/500 | Loss: 149.61063846632055 | Accuracy: 0.9694128408896003\n",
            "Epoch: 151 | The test data Accuracy = 0.9487882944673068 | Test Loss = 13.775890350341797\n",
            "Epoch: 161/500 | Loss: 147.52934682800583 | Accuracy: 0.9680978789091533\n",
            "Epoch: 171/500 | Loss: 150.82263937592506 | Accuracy: 0.9666685724086673\n",
            "Epoch: 181/500 | Loss: 151.6973867855574 | Accuracy: 0.9668972614487451\n",
            "Epoch: 191/500 | Loss: 149.59078529869257 | Accuracy: 0.9669544337087645\n",
            "Epoch: 201/500 | Loss: 148.72179803565928 | Accuracy: 0.9672974672688811\n",
            "Model saved at test accuracy =  0.9563328760859625\n",
            "Epoch: 201 | The test data Accuracy = 0.9563328760859625 | Test Loss = 13.389705657958984\n",
            "Epoch: 211/500 | Loss: 145.40136915445328 | Accuracy: 0.9684409124692699\n",
            "Epoch: 221/500 | Loss: 149.77921864860937 | Accuracy: 0.9670687782288034\n",
            "Epoch: 231/500 | Loss: 147.63551057169312 | Accuracy: 0.96741181178892\n",
            "Epoch: 241/500 | Loss: 152.87843213583292 | Accuracy: 0.9662111943285118\n",
            "Epoch: 251/500 | Loss: 148.03166986452905 | Accuracy: 0.9668972614487451\n",
            "Epoch: 251 | The test data Accuracy = 0.9494741655235482 | Test Loss = 13.24715805053711\n",
            "Epoch: 261/500 | Loss: 145.6310684429972 | Accuracy: 0.9686696015093477\n",
            "Epoch: 271/500 | Loss: 148.97776105411742 | Accuracy: 0.9673546395289006\n",
            "Epoch: 281/500 | Loss: 148.87385118870358 | Accuracy: 0.9687267737693671\n",
            "Epoch: 291/500 | Loss: 147.92682389326785 | Accuracy: 0.9671831227488422\n",
            "Epoch: 301/500 | Loss: 147.03149924623338 | Accuracy: 0.9681550511691727\n",
            "Epoch: 301 | The test data Accuracy = 0.952217649748514 | Test Loss = 13.20400619506836\n",
            "Epoch: 311/500 | Loss: 151.23007812076494 | Accuracy: 0.9679835343891144\n",
            "Epoch: 321/500 | Loss: 147.9528056308627 | Accuracy: 0.9685552569893088\n",
            "Epoch: 331/500 | Loss: 149.5575882753259 | Accuracy: 0.96741181178892\n",
            "Epoch: 341/500 | Loss: 144.4813734347883 | Accuracy: 0.9670687782288034\n",
            "Epoch: 351/500 | Loss: 148.35314669342418 | Accuracy: 0.9678691898690756\n",
            "Epoch: 351 | The test data Accuracy = 0.9494741655235482 | Test Loss = 14.249914169311523\n",
            "Epoch: 361/500 | Loss: 148.91696689944519 | Accuracy: 0.9668400891887257\n",
            "Epoch: 371/500 | Loss: 151.77680640785317 | Accuracy: 0.9663827111085701\n",
            "Epoch: 381/500 | Loss: 144.54284724710803 | Accuracy: 0.9703275970499113\n",
            "Epoch: 391/500 | Loss: 149.86445246636868 | Accuracy: 0.9668400891887257\n",
            "Epoch: 401/500 | Loss: 148.11032281423869 | Accuracy: 0.9679835343891144\n",
            "Epoch: 401 | The test data Accuracy = 0.9561042524005487 | Test Loss = 13.561095237731934\n",
            "Epoch: 411/500 | Loss: 147.9738869533727 | Accuracy: 0.9690126350694643\n",
            "Epoch: 421/500 | Loss: 148.53856660425663 | Accuracy: 0.9667829169287062\n",
            "Epoch: 431/500 | Loss: 149.72364550083876 | Accuracy: 0.9655251272082785\n",
            "Epoch: 441/500 | Loss: 149.40212834038232 | Accuracy: 0.9678120176090561\n",
            "Epoch: 451/500 | Loss: 147.77183964142674 | Accuracy: 0.967926362129095\n",
            "Epoch: 451 | The test data Accuracy = 0.9535893918609968 | Test Loss = 13.142525672912598\n",
            "Epoch: 461/500 | Loss: 145.99476348726373 | Accuracy: 0.9684980847292893\n",
            "Epoch: 471/500 | Loss: 148.94963316462542 | Accuracy: 0.9683837402092504\n",
            "Epoch: 481/500 | Loss: 145.51932437953195 | Accuracy: 0.9691269795895032\n",
            "Epoch: 491/500 | Loss: 150.8211040089005 | Accuracy: 0.9682693956892116\n",
            "Epoch: 500/500 | Loss: 145.20796540301097 | Accuracy: 0.9692984963695614\n",
            "Accuracy: 0.9577\n",
            "Precision: 0.8626\n",
            "Recall: 0.8000\n",
            "F1 Score: 0.8301\n",
            "AUROC Score: 0.8905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### inference"
      ],
      "metadata": {
        "id": "rLWk6CaNp7Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data=pd.read_excel('/content/Fall 2025 3.25.25_processed_norm.xlsx')\n",
        "# inputs=data.drop(['Application Reference ID','admitted'],axis=1).to_numpy()\n",
        "# labels=data['admitted'].to_numpy()\n",
        "# app_id=data['Application Reference ID']\n",
        "# inputs=torch.from_numpy(inputs).float()\n",
        "# unique_majors = int(inputs[:, 0].max()) + 1  # 112\n",
        "# unique_highschools = int(inputs[:, 4].max()) + 1\n",
        "# print(inputs.shape[1],unique_majors,unique_highschools)\n",
        "# #make sure to convert the type to long as tensors deal with the long integer which are 64 bit not the 32 bit\n",
        "# labels=torch.from_numpy(labels).long()\n",
        "\n",
        "# unique_majors=112  # 112\n",
        "# unique_highschools = 4002 #4002\n",
        "\n",
        "\n",
        "# inputs=inputs.shape[1]\n",
        "# layer_sizes = [inputs, 512, 16, 2]  # [input_size, hidden_1, hidden_2, output_size]\n",
        "# use_dout = (True, 0.5)  # Use dropout with a probability of 0.5\n",
        "\n",
        "\n",
        "data=pd.read_excel('/content/Fall 2025 3.25.25_processed_norm.xlsx')\n",
        "inference_inputs=data.drop(['Application Reference ID','admitted'],axis=1).to_numpy()\n",
        "labels=data['admitted'].to_numpy()\n",
        "app_id=data['Application Reference ID']\n",
        "inference_inputs=torch.from_numpy(inference_inputs).float()\n",
        "unique_majors = int(inference_inputs[:, 0].max()) + 1  # 112\n",
        "unique_highschools = int(inference_inputs[:, 4].max()) + 1\n",
        "print(inference_inputs.shape[1],unique_majors,unique_highschools)\n",
        "#make sure to convert the type to long as tensors deal with the long integer which are 64 bit not the 32 bit\n",
        "labels=torch.from_numpy(labels).long()\n",
        "unique_majors=112  # 112\n",
        "unique_highschools = 4002 #4002\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu_1N3zIqFTU",
        "outputId": "45afcbe5-ff62-4d57-fd10-9e1006c6bc84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 106 3046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "class ConvexNet(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ConvexNet, self).__init__()\n",
        "        torch.manual_seed(2)\n",
        "\n",
        "        self.embedding_dim = 300\n",
        "        unique_majors, unique_highschools = kwargs[\"unique_majors\"], kwargs[\"unique_highschools\"]\n",
        "\n",
        "\n",
        "        layer_sizes = kwargs[\"size\"] # [n_input, n_hidden_1, n_hidden_2, n_output]\n",
        "        # inputs = layer_sizes[0]\n",
        "        # print(layer_sizes[0])\n",
        "        layer_sizes[0]=(inputs- 2 + 2*self.embedding_dim)\n",
        "        # print(layer_sizes[0])\n",
        "        # Embedding layers for the categorical variables\n",
        "        self.major_embedding = nn.Embedding(unique_majors, self.embedding_dim)\n",
        "        self.hs_embedding = nn.Embedding(unique_highschools, self.embedding_dim)\n",
        "\n",
        "\n",
        "        self.W = nn.ParameterList([nn.Parameter(torch.Tensor(l, layer_sizes[0]))\n",
        "                                   for l in layer_sizes[1:]])\n",
        "        self.U = nn.ParameterList([nn.Parameter(torch.Tensor(layer_sizes[i + 1], layer_sizes[i]))\n",
        "                                   for i in range(1, len(layer_sizes) - 1)])\n",
        "        self.bias = nn.ParameterList([nn.Parameter(torch.Tensor(layer_sizes[i+1])) for i in range(len(layer_sizes)-1)])\n",
        "\n",
        "        self.act = F.relu\n",
        "        self.use_dout = kwargs[\"use_dout\"][0]\n",
        "        self.dropout = nn.Dropout(p=kwargs[\"use_dout\"][1])\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Initialize weights using kaiming initialization\n",
        "        for W in self.W:\n",
        "            nn.init.kaiming_uniform_(W, a=5 ** 0.5)\n",
        "        for U in self.U:\n",
        "            nn.init.kaiming_uniform_(U, a=5 ** 0.5)\n",
        "        for i, b in enumerate(self.bias):\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W[i])\n",
        "            bound = 1 / (fan_in ** 0.5)\n",
        "            nn.init.uniform_(b, -bound, bound)\n",
        "    def forward(self, x):\n",
        "        # Separate the categorical and continuous inputs\n",
        "        categorical_input_1 = x[:, 0].long()  # Application Major\n",
        "        categorical_input_2 = x[:, 4].long()  # High school input (another categorical feature)\n",
        "\n",
        "        continuous_indices = [i for i in range(x.shape[1]) if i not in [0, 4]]\n",
        "        continuous_input = x[:, continuous_indices].float()  # The rest: continuous features\n",
        "\n",
        "        # Apply embedding layers for categorical inputs\n",
        "        major_embeddings = self.major_embedding(categorical_input_1)\n",
        "        #print(major_embeddings.shape)\n",
        "        hs_embeddings = self.hs_embedding(categorical_input_2)\n",
        "        #print(hs_embeddings.shape)\n",
        "        # Concatenate embeddings with continuous inputs\n",
        "        x = torch.cat((major_embeddings, hs_embeddings, continuous_input), dim=1)\n",
        "        #print(x.shape)\n",
        "\n",
        "        z = F.linear(x, self.W[0], self.bias[0])\n",
        "        z = self.act(z)\n",
        "        if self.use_dout:\n",
        "            z = self.dropout(z)\n",
        "\n",
        "        for W, b, U in zip(self.W[1:-1], self.bias[1:-1], self.U[:-1]):\n",
        "            z = F.linear(x, W, b) + F.linear(z, F.softplus(U)) / U.shape[0]\n",
        "            z = self.act(z)\n",
        "            if self.use_dout:\n",
        "                z = self.dropout(z)\n",
        "\n",
        "        out = F.linear(x, self.W[-1], self.bias[-1]) + F.linear(z, F.softplus(self.U[-1])) / self.U[-1].shape[0]\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "net = ConvexNet(size=layer_sizes, unique_majors=unique_majors, unique_highschools=unique_highschools, use_dout=use_dout)\n",
        "\n",
        "# Print the model architecture (optional)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEmMpWRlsO_m",
        "outputId": "b7740e94-a68f-495c-814b-6bdbafef60cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvexNet(\n",
            "  (major_embedding): Embedding(112, 300)\n",
            "  (hs_embedding): Embedding(4002, 300)\n",
            "  (W): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512x647]\n",
            "      (1): Parameter containing: [torch.float32 of size 16x647]\n",
            "      (2): Parameter containing: [torch.float32 of size 2x647]\n",
            "  )\n",
            "  (U): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 16x512]\n",
            "      (1): Parameter containing: [torch.float32 of size 2x16]\n",
            "  )\n",
            "  (bias): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512]\n",
            "      (1): Parameter containing: [torch.float32 of size 16]\n",
            "      (2): Parameter containing: [torch.float32 of size 2]\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "net.load_state_dict(torch.load('/content/best.pth'))\n",
        "# Perform inference on the new data\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    # Assuming your model is saved in 'save_net' after training\n",
        "    outputs = net(inference_inputs)\n",
        "\n",
        "# Get predicted class labels from the outputs\n",
        "predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "# If you want the predicted probabilities, you can use:\n",
        "# probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "# Convert predictions to numpy for further processing\n",
        "predictions = predictions.numpy()\n",
        "\n",
        "print(\"Predictions on new data:\")\n",
        "print(predictions)\n",
        "total_predictions=len(predictions)\n",
        "count_ones = (predictions == 1).sum()\n",
        "print(f\"Number of 1s in predictions: {count_ones}\")\n",
        "print(f\"Number of 0s in predictions: {total_predictions - count_ones}\")\n",
        "print(f\"Total number of predictions: {total_predictions}\")\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(labels,predictions)\n",
        "precision = precision_score(labels,predictions)\n",
        "recall = recall_score(labels, predictions)\n",
        "f1_val = f1_score(labels, predictions)\n",
        "auc_roc = roc_auc_score(labels, predictions)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_val))\n",
        "print('AUROC Score: {:.4f}'.format(auc_roc))\n",
        "\n",
        "\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(labels,predictions)\n",
        "\n",
        "# Print the matrix\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot the Confusion Matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(labels,predictions)\n",
        "\n",
        "# Extract TP, TN, FP, FN\n",
        "TN = cm[0, 0]  # True Negative\n",
        "FP = cm[0, 1]  # False Positive\n",
        "FN = cm[1, 0]  # False Negative\n",
        "TP = cm[1, 1]  # True Positive\n",
        "\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "QxQ17dVQH56K",
        "outputId": "3ad92ac3-0f29-46f3-eb91-2d58533aa321"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on new data:\n",
            "[0 0 0 ... 0 0 1]\n",
            "Number of 1s in predictions: 949\n",
            "Number of 0s in predictions: 11356\n",
            "Total number of predictions: 12305\n",
            "Accuracy: 0.9365\n",
            "Precision: 0.2982\n",
            "Recall: 0.7111\n",
            "F1 Score: 0.4202\n",
            "AUROC Score: 0.8276\n",
            "Confusion Matrix:\n",
            " [[11241   666]\n",
            " [  115   283]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives (TP): 283\n",
            "False Positives (FP): 666\n",
            "True Negatives (TN): 11241\n",
            "False Negatives (FN): 115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gxd2OH7WIAZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}